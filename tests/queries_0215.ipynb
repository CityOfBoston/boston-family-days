{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests, os\n",
    "from dotenv import load_dotenv\n",
    "from fetch_all_data import registration_data, demographic_data\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more pages to fetch from https://us-central1-boston-family-days---prod.cloudfunctions.net/getRegistrationData\n",
      "Fetched 10990 registration records.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Fetched {len(registration_data)} registration records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more pages to fetch from https://us-central1-boston-family-days---prod.cloudfunctions.net/getDemographicData\n",
      "Fetched 8935 demographic records.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Fetched {len(demographic_data)} demographic records.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preferred Language Distribution:\n",
      "                                Count  Percentage\n",
      "preferredCommunicationLanguage                   \n",
      "english                         10740        97.7\n",
      "spanish-latin-american            177         1.6\n",
      "mandarin                           26         0.2\n",
      "haitian-creole                     17         0.2\n",
      "cantonese                           8         0.1\n",
      "portuguese-brazilian                8         0.1\n",
      "vietnamese                          7         0.1\n",
      "cabo-verdean-creole                 3         0.0\n",
      "french-european                     2         0.0\n",
      "arabic-standard                     1         0.0\n",
      "somali                              1         0.0\n",
      "\n",
      "Number of Duplicate Student Entries (same first and last name, different emails):\n",
      "Count: 210, Percentage: 3.8%\n",
      "\n",
      "Number of Students per Email Address:\n",
      "    Count  Percentage\n",
      "1    5953        73.1\n",
      "2    1704        20.9\n",
      "3     358         4.4\n",
      "4      92         1.1\n",
      "5      19         0.2\n",
      "6       7         0.1\n",
      "7       2         0.0\n",
      "8       2         0.0\n",
      "9       1         0.0\n",
      "11      1         0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the fetched data into DataFrames\n",
    "registration_df = pd.DataFrame(registration_data)\n",
    "demographic_df = pd.DataFrame(demographic_data)\n",
    "\n",
    "# Perform an outer join on the 'passId' column\n",
    "merged_df = pd.merge(registration_df, demographic_df, on='passId', how='outer')\n",
    "\n",
    "# Normalize email addresses by trimming spaces and converting to lowercase\n",
    "merged_df['email'] = merged_df['email'].str.strip().str.lower()\n",
    "\n",
    "# 1. Distribution of preferred languages (default to 'english' if empty)\n",
    "merged_df['preferredCommunicationLanguage'] = merged_df['preferredCommunicationLanguage'].fillna('english')\n",
    "language_counts = merged_df['preferredCommunicationLanguage'].value_counts()\n",
    "language_percentages = (language_counts / language_counts.sum() * 100).round(1)\n",
    "language_distribution = pd.DataFrame({\n",
    "    'Count': language_counts,\n",
    "    'Percentage': language_percentages\n",
    "})\n",
    "print(\"Preferred Language Distribution:\")\n",
    "print(language_distribution)\n",
    "\n",
    "# 2. Count and percentage of duplicate students (same first and last name) for different email addresses\n",
    "duplicate_students = merged_df.groupby(['firstName', 'lastName']).email.nunique()\n",
    "duplicate_students_count = duplicate_students[duplicate_students > 1].sum()  # Total number of duplicate entries\n",
    "total_entries = len(merged_df)\n",
    "duplicate_students_percentage = ((duplicate_students_count * 2 / total_entries) * 100).round(1)\n",
    "print(\"\\nNumber of Duplicate Student Entries (same first and last name, different emails):\")\n",
    "print(f\"Count: {duplicate_students_count}, Percentage: {duplicate_students_percentage:.1f}%\")\n",
    "\n",
    "# 3. Number and percentage of students under the same email addresses\n",
    "students_per_email = merged_df.groupby('email').size()\n",
    "email_distribution_counts = students_per_email.value_counts().sort_index()\n",
    "email_distribution_percentages = (email_distribution_counts / email_distribution_counts.sum() * 100).round(1)\n",
    "email_distribution = pd.DataFrame({\n",
    "    'Count': email_distribution_counts,\n",
    "    'Percentage': email_distribution_percentages\n",
    "})\n",
    "print(\"\\nNumber of Students per Email Address:\")\n",
    "print(email_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Field Completeness Percentages:\n",
      "                             Field  Completeness (%)\n",
      "0                             id_x             100.0\n",
      "1                            email             100.0\n",
      "2                        firstName             100.0\n",
      "5                         lastName             100.0\n",
      "6   preferredCommunicationLanguage             100.0\n",
      "8                      createdAt_x             100.0\n",
      "10                          passId             100.0\n",
      "11                          school             100.0\n",
      "12                          status             100.0\n",
      "4                   parentLastName              99.9\n",
      "9                        profileId              99.7\n",
      "3                  parentFirstName              98.9\n",
      "26                     createdAt_y              81.3\n",
      "14                            id_y              81.3\n",
      "28                       studentId              50.6\n",
      "20                           grade              48.0\n",
      "7                      phoneNumber              29.4\n",
      "18                             zip              28.1\n",
      "19                             dob              28.1\n",
      "21                  englishLearner              28.1\n",
      "25                             iep              28.1\n",
      "15                         street1              23.5\n",
      "17                    neighborhood              23.5\n",
      "22                            race              23.5\n",
      "23                       ethnicity              23.5\n",
      "24                        programs              23.5\n",
      "27            languageSpokenAtHome              23.5\n",
      "16                         street2              10.8\n",
      "13                      middleName               5.2\n"
     ]
    }
   ],
   "source": [
    "# Calculate completeness percentage for each field\n",
    "def calculate_completeness(df):\n",
    "    \"\"\"Calculate the percentage of non-null values for each column in the DataFrame.\"\"\"\n",
    "    total_rows = len(df)\n",
    "    completeness = {}\n",
    "    \n",
    "    for column in df.columns:\n",
    "        non_null_count = df[column].count()  # Count non-null values\n",
    "        completeness[column] = round((non_null_count / total_rows) * 100, 1)\n",
    "    \n",
    "    # Convert to DataFrame and sort by completeness percentage\n",
    "    completeness_df = pd.DataFrame({\n",
    "        'Field': completeness.keys(),\n",
    "        'Completeness (%)': completeness.values()\n",
    "    }).sort_values('Completeness (%)', ascending=False)\n",
    "    \n",
    "    return completeness_df\n",
    "\n",
    "# Calculate and display completeness for all fields\n",
    "field_completeness = calculate_completeness(merged_df)\n",
    "print(\"\\nField Completeness Percentages:\")\n",
    "print(field_completeness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "School distribution:\n",
      "school\n",
      "                                                     133\n",
      "Academy of the Pacific Rim Charter Public School     507\n",
      "Bridge Boston Charter School                         330\n",
      "Brooke Charter School                               2188\n",
      "Conservatory Lab Charter School                      448\n",
      "                                                    ... \n",
      "xb                                                     1\n",
      "yeshiva-ohr-yisrael                                    4\n",
      "ymca                                                   1\n",
      "ymca-parkway                                           1\n",
      "young-achievers-k-8-school                             4\n",
      "Name: count, Length: 536, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get unique schools and sort them alphabetically\n",
    "unique_schools = merged_df['school'].unique()\n",
    "unique_schools.sort()\n",
    "\n",
    "# Print the list of unique schools\n",
    "# print(\"Unique schools:\")\n",
    "# for school in unique_schools:\n",
    "#     print(school)\n",
    "\n",
    "# Alternatively, if you want to see the count of students per school:\n",
    "school_counts = merged_df['school'].value_counts().sort_index()\n",
    "print(\"\\nSchool distribution:\")\n",
    "print(school_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36 matching records\n",
      "\n",
      "Matched schools distribution:\n",
      "matched_school\n",
      "Torah Academy          32\n",
      "Yeshiva Ohr Yisrael     4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from thefuzz import fuzz\n",
    "import re\n",
    "import json\n",
    "\n",
    "def normalize_school_name(name):\n",
    "    \"\"\"Normalize school name by removing special characters, spaces, and converting to lowercase\"\"\"\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    return re.sub(r'[^a-zA-Z0-9]', '', name.lower())\n",
    "\n",
    "def extract_readable_date(date_str):\n",
    "    \"\"\"Extract readable date from JSON string\"\"\"\n",
    "    if pd.isna(date_str):\n",
    "        return None\n",
    "    try:\n",
    "        # Handle both string and dictionary inputs\n",
    "        if isinstance(date_str, str):\n",
    "            date_dict = json.loads(date_str.replace(\"'\", '\"'))\n",
    "        elif isinstance(date_str, dict):\n",
    "            date_dict = date_str\n",
    "        else:\n",
    "            return str(date_str)\n",
    "            \n",
    "        return date_dict.get('readable')\n",
    "    except Exception as e:\n",
    "        # If there's an error, return the original string\n",
    "        return str(date_str) if date_str else None\n",
    "\n",
    "def fuzzy_match_schools(df, target_schools, threshold=80):\n",
    "    \"\"\"\n",
    "    Perform fuzzy matching on school names\n",
    "    threshold: minimum similarity score (0-100) to consider a match\n",
    "    \"\"\"\n",
    "    # Create a working copy of the dataframe\n",
    "    working_df = df.copy()\n",
    "    \n",
    "    # Handle createdAt fields\n",
    "    working_df['createdAt'] = working_df['createdAt_x'].apply(extract_readable_date)\n",
    "    working_df['createdAt'] = working_df.apply(\n",
    "        lambda x: x['createdAt'] if pd.notna(x['createdAt']) \n",
    "        else extract_readable_date(x['createdAt_y']), axis=1\n",
    "    )\n",
    "    \n",
    "    # Drop the original createdAt columns\n",
    "    working_df = working_df.drop(['createdAt_x', 'createdAt_y'], axis=1)\n",
    "    \n",
    "    # Normalize target schools\n",
    "    normalized_targets = [normalize_school_name(school) for school in target_schools]\n",
    "    target_map = dict(zip(normalized_targets, target_schools))\n",
    "    \n",
    "    # Function to find best match\n",
    "    def find_best_match(school_name):\n",
    "        normalized_name = normalize_school_name(school_name)\n",
    "        best_score = 0\n",
    "        best_match = None\n",
    "        \n",
    "        for target in normalized_targets:\n",
    "            score = fuzz.ratio(normalized_name, target)\n",
    "            if score > best_score and score >= threshold:\n",
    "                best_score = score\n",
    "                best_match = target_map[target]\n",
    "        \n",
    "        return best_match if best_match else None\n",
    "\n",
    "    # Add matched school column\n",
    "    working_df['matched_school'] = working_df['school'].apply(find_best_match)\n",
    "    \n",
    "    # Filter rows where we found a match\n",
    "    matched_df = working_df[working_df['matched_school'].notna()].copy()\n",
    "    \n",
    "    return matched_df\n",
    "\n",
    "# List of target schools\n",
    "target_schools = [\n",
    "    \"Torah Academy\",\n",
    "    \"Yeshiva Ohr Yisrael\"\n",
    "]\n",
    "\n",
    "# Perform fuzzy matching\n",
    "matched_data = fuzzy_match_schools(merged_df, target_schools)\n",
    "\n",
    "# Export to CSV\n",
    "matched_data.to_csv('catholic_schools_data.csv', index=False)\n",
    "\n",
    "# Print summary\n",
    "print(f\"Found {len(matched_data)} matching records\")\n",
    "print(\"\\nMatched schools distribution:\")\n",
    "print(matched_data['matched_school'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all school counts to txt file\n",
    "with open('school_counts.txt', 'w') as f:\n",
    "    f.write(school_counts.to_string())\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
